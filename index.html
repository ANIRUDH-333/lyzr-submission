<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Anirudh Edpuganti - Education Engineer Submission</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Simple styling for the <details> summary to act as an accordion */
        summary {
            cursor: pointer;
            list-style: none;
            /* Remove default marker */
        }

        summary::-webkit-details-marker {
            display: none;
            /* Hide marker for Chrome/Safari */
        }

        summary:focus {
            outline: none;
        }

        /* Add a custom marker */
        summary:before {
            content: '►';
            margin-right: 0.5rem;
            font-size: 0.8em;
            transition: transform 0.2s ease-in-out;
        }

        details[open] summary:before {
            transform: rotate(90deg);
        }

        /* Style for analogies */
        .analogy {
            background-color: #ffffff;
            border-left: 4px solid #000000;
            padding: 1rem;
            margin: 1rem 0;
            border-radius: 0.25rem;
            border: 1px solid #e5e5e5;
        }

        .analogy-title {
            font-weight: 600;
            color: #000000;
            display: block;
            margin-bottom: 0.5rem;
        }

        /* Style for labs */
        .lab {
            background-color: #ffffff;
            border-left: 4px solid #000000;
            padding: 1rem;
            margin: 1rem 0;
            border-radius: 0.25rem;
            border: 1px solid #e5e5e5;
        }

        .lab-title {
            font-weight: 600;
            color: #000000;
            display: block;
            margin-bottom: 0.5rem;
        }

        /* Add Inter font */
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');

        body {
            font-family: 'Inter', sans-serif;
            background-color: #ffffff;
            color: #000000;
        }
    </style>
</head>

<body class="antialiased">

    <div class="container mx-auto max-w-4xl p-5 md:p-10">

        <!-- Header -->
        <header class="mb-10">
            <h1 class="text-3xl md:text-4xl font-bold text-black">Education Engineer Submission</h1>
            <p class="mt-2 text-lg text-gray-600">By Anirudh Edpuganti</p>
            <p class="mt-4 text-black">Thank you for the opportunity. Below is my proposed 4-week curriculum for the
                "Agent Building for Developers" course (Part 1), along with my 3-minute teaching video (Part 2).</p>
        </header>

        <!-- Part 1: The 4-Week Curriculum -->
        <section class="mb-12">
            <h2 class="text-2xl font-semibold text-black mb-6">Part 1: 4-Week Course Curriculum</h2>

            <div class="space-y-4">

                <!-- Week 1 -->
                <details class="bg-white border border-gray-200 p-6 rounded-lg shadow-sm border border-gray-200">
                    <summary class="text-xl font-semibold text-black">
                        Week 1: The Agentic Leap – From Prompting to Problem-Solving
                    </summary>
                    <div class="mt-4 prose prose-slate max-w-none text-black">
                        <p class="text-lg"><strong>Weekly Goal:</strong> To "demystify" AI Agents by answering the
                            critical "Why?" and "What?". By the end of this week, you will move from being a developer
                            who uses an LLM to a developer who understands how to automate with an LLM. You will build
                            your first simple agent from scratch, with no magic frameworks.</p>

                        <hr class="my-4">

                        <h3 class="font-semibold text-lg text-black">Module 1.1: Why Agents? The Shift from
                            Instruction to Intention</h3>
                        <p><strong>Concept:</strong> This module is our "Why?". Before we write any code, we must
                            establish why agents are the necessary next step. We'll explore the limitations of
                            single-call LLMs (like a standard ChatGPT prompt) for any complex, multi-step task. We are
                            moving from a world of giving instructions to a world of defining intent.</p>

                        <div class="analogy">
                            <span class="analogy-title">Developer Analogy: The REPL vs. The Ansible Script</span>
                            <p>A "one-shot" LLM call is like a <strong>REPL (Read-Eval-Print Loop)</strong>: You type
                                <code>2 + 2</code> and it returns <code>4</code>. You ask a question, it gives an
                                answer. It's a powerful, single-turn "Read-Eval-Print" cycle. But it's passive. It has
                                no state and cannot act on its own.
                            </p>
                            <p>An <strong>AI Agent</strong> is like an <strong>Ansible Playbook</strong> or a
                                <strong>Terraform Script</strong>: You don't tell it how to do every step. You give it a
                                goal (e.g., "ensure this server is configured," "get me a brief on Company X"). The
                                script then autonomously observes the current state, thinks about the steps needed, and
                                acts to achieve the desired state. It can run commands, check results, and loop until
                                the goal is met.
                            </p>
                        </div>

                        <div class="bg-green-50 border-l-4 border-green-500 p-4 my-4 rounded">
                            <h4 class="font-semibold text-green-800 mb-2">Key Learning:</h4>
                            <ul class="list-disc pl-5 text-green-700">
                                <li>LLMs are passive "brains" that respond to instructions.</li>
                                <li>Agents are active systems that execute on intent.</li>
                                <li>Agents are designed to automate complex, multi-step workflows that LLMs alone cannot
                                    handle.</li>
                            </ul>
                        </div>

                        <div class="lab">
                            <span class="lab-title">Hands-On Lab 1.1: The "Wow" Demo & The "Human Agent" Exercise</span>
                            <p><strong>Demo:</strong> We will show a side-by-side comparison of a "Manual" vs. "Agentic"
                                workflow (e.g., "Research the top 3 competitors for Lyzr AI and summarize their main
                                products"). We'll show the manual process (Googling, opening tabs, reading,
                                copy-pasting) vs. a single prompt to an agent that does the same.</p>
                            <p><strong>Exercise:</strong> You will be the agent. We'll give you a task: "Find the best
                                Python library for PDF parsing that was released in the last 6 months." You will write
                                down the exact, literal steps you would take (e.g., "1. Go to Google. 2. Search for 'new
                                python pdf library 2024'. 3. Open the top 5 links..."). This exercise forces you to see
                                the "program" an agent needs to run.</p>
                        </div>

                        <h3 class="font-semibold text-lg text-black mt-6">Module 1.2: Deconstructing the "Magic": An
                            Agent's Anatomy</h3>
                        <p><strong>Concept:</strong> We'll pull back the curtain and show that an agent is not a magical
                            black box. It's a simple, elegant programming loop that you already understand. We will
                            introduce the core loop of all agents: <strong>Observe, Think, Act (OTA)</strong>.</p>

                        <div class="analogy">
                            <span class="analogy-title">Developer Analogy: An Agent is Just a while Loop</span>
                            <p>An agent's "magic" is just a while loop that uses an LLM to decide what to do next.</p>
                            <pre class="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto text-sm"><code># This is the core logic of almost every agent
goal = "What's the weather in London?"
history = [] # Our "state"
goal_achieved = False

while not goal_achieved:
    # 1. THINK: The LLM acts as a router or planner
    prompt = f"Given history: {history}, what's the next step to achieve: {goal}?"
    llm_response = llm.call(prompt) 
    
    # 2. ACT: We parse the LLM's response
    if llm_response.says_final_answer():
        print(llm_response.answer)
        goal_achieved = True
    
    elif llm_response.wants_to_use_tool("get_weather"):
        city = llm_response.get_parameter("city")
        
        # 3. OBSERVE: We run the tool and get the result
        weather_data = get_weather(city)
        history.append(f"Tool Result: {weather_data}")
        
    # The loop repeats, feeding the new observation back to the LLM</code></pre>
                        </div>

                        <div class="bg-green-50 border-l-4 border-green-500 p-4 my-4 rounded">
                            <h4 class="font-semibold text-green-800 mb-2">Key Learning:</h4>
                            <ul class="list-disc pl-5 text-green-700">
                                <li>The "Observe, Think, Act" (OTA) loop is the fundamental pattern of all agentic
                                    systems.</li>
                                <li>The LLM's role shifts from being an answerer to being a planner or router that
                                    decides the next step.</li>
                                <li>A "Thought" is just the LLM's reasoning, often in a structured format like JSON,
                                    that explains its plan and what action (or tool) to use next.</li>
                            </ul>
                        </div>

                        <div class="lab">
                            <span class="lab-title">Hands-On Lab 1.2: Pseudocode the OTA Loop</span>
                            <p><strong>Task:</strong> Using the "Human Agent" exercise from Lab 1.1 ("find the best
                                Python PDF library..."), you will now write the pseudocode for an agent that can
                                accomplish it.</p>
                            <p><strong>Goal:</strong> You must use the while loop structure. Define what your "tools"
                                would be (e.g., <code>google_search(query)</code>, <code>read_webpage(url)</code>) and
                                write the if/elif logic inside your loop to show how the agent would "Think" and "Act."
                            </p>
                        </div>

                        <h3 class="font-semibold text-lg text-black mt-6">Module 1.3: "Hello, Agent!" – Building Your
                            First Agent from Scratch</h3>
                        <p><strong>Concept:</strong> This is where the confidence is built. We will build a real,
                            working agent using only standard Python and an LLM API key. No frameworks, no libraries, no
                            magic. This lab proves that all the concepts from Modules 1.1 and 1.2 are just simple,
                            understandable code.</p>

                        <div class="analogy">
                            <span class="analogy-title">Developer Analogy: No Frameworks, No Magic</span>
                            <p>This is the "learn to build a web server with Python's basic <code>http.server</code>" of
                                agent development. Before you use a complex framework like Django or Flask, you must
                                understand the raw request/response cycle. By building this "from scratch," you will
                                know what the frameworks are doing for you later.</p>
                        </div>

                        <div class="bg-green-50 border-l-4 border-green-500 p-4 my-4 rounded">
                            <h4 class="font-semibold text-green-800 mb-2">Key Learning:</h4>
                            <ul class="list-disc pl-5 text-green-700">
                                <li>An agent is just a Python script with a loop and a list to manage history (state).
                                </li>
                                <li>A "Tool" is just a Python function you write and describe in the system prompt.</li>
                                <li>The System Prompt is the "operating system" for your agent. It defines the rules,
                                    the goal, and the "API" of the tools the agent is allowed to call.</li>
                            </ul>
                        </div>

                        <div class="lab">
                            <span class="lab-title">Hands-On Lab 1.3: The "No-Magic" Weather Agent</span>
                            <p><strong>Task:</strong> You will write a single Python script (<code>agent.py</code>) that
                                can answer the question: "What's the weather in London?"</p>

                            <div class="mt-3">
                                <h5 class="font-semibold text-black mb-2">Requirements:</h5>
                                <ol class="list-decimal pl-5 space-y-2">
                                    <li>You will write a simple Python function <code>get_weather(city)</code>. (It can
                                        just return a hard-coded JSON string like
                                        <code>{"city": "London", "temp": "15C"}</code> for this lab).
                                    </li>
                                    <li>You will write a <code>system_prompt</code> that tells the LLM: "You are a
                                        helpful assistant. You have one tool: get_weather(city). When asked about the
                                        weather, you MUST reply only with a JSON object in the format: {"thought":
                                        "...", "action": "get_weather", "city": "..."}. If you have the final answer,
                                        reply with: {"thought": "...", "final_answer": "..."}"</li>
                                    <li>You will write the while loop that:
                                        <ul class="list-disc pl-5 mt-2 space-y-1">
                                            <li>Calls the LLM with the user query and prompt.</li>
                                            <li>Parses the LLM's JSON response.</li>
                                            <li>If it sees an "action", it calls your local <code>get_weather</code>
                                                function.</li>
                                            <li>It then takes the function's output and feeds it back into the LLM in
                                                the next loop.</li>
                                            <li>It continues until the LLM returns a <code>final_answer</code>.</li>
                                        </ul>
                                    </li>
                                </ol>
                            </div>
                        </div>
                    </div>
                </details>

                <!-- Week 2 -->
                <details class="bg-white border border-gray-200 p-6 rounded-lg shadow-sm border border-gray-200">
                    <summary class="text-xl font-semibold text-black">
                        Week 2: Giving Agents Memory - The Power of RAG
                    </summary>
                    <div class="mt-4 prose prose-slate max-w-none text-black">
                        <p class="text-lg"><strong>Weekly Goal:</strong> To solve the agent "amnesia problem." You will
                            learn the difference between short-term conversational memory and long-term knowledge
                            memory. By the end of this week, you will understand and build the most critical pattern in
                            agentic AI: <strong>Retrieval-Augmented Generation (RAG)</strong>, allowing your agents to
                            access and reason about external data (like your own documents).</p>

                        <hr class="my-4">

                        <h3 class="font-semibold text-lg text-black">Module 2.1: The Amnesia Problem (Short-Term
                            Memory)</h3>
                        <p><strong>Concept:</strong> We'll start by defining the problem. LLMs are, by default,
                            stateless. Every API call is completely independent, like a curl request to a REST API. It
                            has no memory of past interactions. This is the "amnesia problem." We'll explore the first
                            and simplest solution: conversational history.</p>

                        <div class="analogy">
                            <span class="analogy-title">Developer Analogy: HTTP vs. Web Sockets (or Sessions)</span>
                            <p>A "stateless" LLM call is like an <strong>HTTP request</strong>: Every single request is
                                new. If you want the server to know who you are, you must pass your entire context (like
                                a JWT or session cookie) with every single call.</p>
                            <p>An agent with "short-term memory" is like a <strong>request.session</strong> object (or a
                                stateful WebSocket): We can store the conversation history in a list (like our history
                                list from Lab 1.3) and pass it back with each new request. This "fakes" a continuous
                                conversation.</p>
                        </div>

                        <div class="bg-green-50 border-l-4 border-green-500 p-4 my-4 rounded">
                            <h4 class="font-semibold text-green-800 mb-2">Key Learning:</h4>
                            <ul class="list-disc pl-5 text-green-700">
                                <li><strong>Problem:</strong> The history list will eventually grow too large and
                                    overflow the LLM's context window (its "RAM"). This is expensive, slow, and will
                                    eventually fail.</li>
                                <li><strong>Solution:</strong> Short-term memory is only for short conversations. We
                                    need a different solution for "long-term memory" (i.e., knowledge).</li>
                            </ul>
                        </div>

                        <div class="lab">
                            <span class="lab-title">Hands-On Lab 2.1: Breaking the Context Window</span>
                            <p><strong>Task:</strong> You will modify your "No-Magic Agent" from Week 1.</p>
                            <p><strong>Goal:</strong> We will simulate a long conversation by pre-filling the history
                                list with 10,000 words of "fake" conversational text.</p>
                            <p><strong>Result:</strong> When you run your agent, you will see the LLM API call fail with
                                a "Context Length Exceeded" error. This lab makes the abstract problem of the context
                                window a tangible, physical bug that you, the developer, must now solve.</p>
                        </div>

                        <h3 class="font-semibold text-lg text-black mt-6">Module 2.2: Long-Term Memory (Embeddings &
                            Vector Databases)</h3>
                        <p><strong>Concept:</strong> Now that we've proven our agent can't "remember" large files, we'll
                            introduce the solution: Vector Databases. To understand them, we must first understand
                            "embeddings."</p>

                        <div class="analogy">
                            <span class="analogy-title">Developer Analogy: A Git Commit Hash</span>
                            <p><strong>What is an Embedding?</strong> It's a way to turn complex data (like text) into a
                                machine-readable signature (a list of numbers, or "vector").</p>
                            <p><strong>The Analogy:</strong> How does Git know if a file has changed? It doesn't diff
                                the whole file every time. It runs the file content through a hash function (SHA-1) to
                                create a unique, fixed-size signature (the "hash").</p>
                            <pre
                                class="bg-white border border-gray-200 p-3 rounded text-sm"><code>"Hello, World!" -> a591a6d40bf420404a011733cfb7b190d62c65bf</code></pre>
                            <p>An <strong>Embedding Model</strong> is just a "hash function" for meaning (semantics). It
                                turns text into a "semantic hash" (a vector) so that similar-meaning texts have
                                similar-looking vectors.</p>
                        </div>

                        <div class="analogy mt-4">
                            <span class="analogy-title">Developer Analogy: SQL LIKE vs. Vector Search</span>
                            <p>A <strong>SQL DB</strong> finds literal matches. If you search for "developer," it will
                                not find "software engineer."</p>
                            <pre
                                class="bg-white border border-gray-200 p-3 rounded text-sm mt-2"><code>SELECT * FROM docs WHERE content LIKE '%developer%';</code></pre>
                            <p>A <strong>Vector DB</strong> finds conceptual or semantic matches. If you search for
                                "developer," it will find "software engineer," "coder," and "programmer" because their
                                "semantic hashes" (vectors) are numerically close in the database.</p>
                        </div>

                        <div class="lab">
                            <span class="lab-title">Hands-On Lab 2.2: "Hello, Vectors!"</span>
                            <p><strong>Task:</strong> We'll use a simple, in-memory vector DB library (like
                                <code>chromadb</code>).
                            </p>
                            <p><strong>Goal:</strong> Prove the concept of semantic search in a few lines of Python.</p>
                            <pre class="bg-gray-900 text-gray-100 p-4 rounded-lg overflow-x-auto text-sm mt-3"><code>db.add(document="The cat is sleeping on the couch.", id="doc1")
db.add(document="The dog is barking in the yard.", id="doc2")
db.add(document="I love to code in Python.", id="doc3")

# Run a query
results = db.query(query_text="What is the feline doing?")</code></pre>
                            <p><strong>Result:</strong> The database will return <code>doc1</code>. This is the "aha!"
                                moment. You searched for "feline" and it found "cat." You now have a database that can
                                search by meaning.</p>
                        </div>

                        <div class="bg-green-50 border-l-4 border-green-500 p-4 my-4 rounded">
                            <h4 class="font-semibold text-green-800 mb-2">Key Learning:</h4>
                            <ul class="list-disc pl-5 text-green-700">
                                <li>Embeddings are "semantic hashes" that turn text into numerical vectors representing
                                    meaning.</li>
                                <li>Vector databases enable semantic search - finding content by meaning rather than
                                    exact word matches.</li>
                                <li>This solves the agent memory problem by allowing agents to retrieve relevant
                                    information from large datasets.</li>
                                <li>Vector search finds "software engineer" when you search for "developer" because
                                    their embeddings are numerically similar.</li>
                            </ul>
                        </div>

                        <h3 class="font-semibold text-lg text-black mt-6">Module 2.3: The "Chat with your Docs" Agent
                            (RAG)</h3>
                        <p><strong>Concept:</strong> This is the payoff. We will now combine our agent loop (Week 1)
                            with our new vector database (Module 2.2) to build a <strong>Retrieval-Augmented Generation
                                (RAG)</strong> agent. This is the pattern for building agents that can "talk to" private
                            data.</p>

                        <div class="analogy">
                            <span class="analogy-title">Developer Analogy: The "Open-Book Exam"</span>
                            <p>A normal LLM call is a "closed-book exam." The LLM can only answer based on what it was
                                trained on (what it "memorized" up to 2023).</p>
                            <p>A <strong>RAG call</strong> is an "open-book exam." The agent isn't asked to know the
                                answer. It's asked to find the answer and summarize it.</p>
                        </div>

                        <div class="bg-white border-l-4 border-gray-600 p-4 my-4 rounded">
                            <h4 class="font-semibold text-black mb-3">The RAG Flow (This is the most important
                                part):</h4>
                            <div class="space-y-3 text-black">
                                <div><strong>User Query:</strong> "What is Lyzr's AgentMesh?"</div>
                                <div>
                                    <strong>Step 1: Retrieve (The SELECT):</strong> The agent does not ask the LLM. It
                                    first asks the Vector DB.
                                    <pre
                                        class="bg-white border border-gray-200 p-2 rounded text-sm mt-1"><code>context_chunks = db.query("What is Lyzr's AgentMesh?")</code></pre>
                                </div>
                                <div><strong>Step 2: Augment (The "Context Stuffing"):</strong> The agent takes the user
                                    query and stuffs the retrieved text chunks into a new prompt.</div>
                                <div><strong>Step 3: Generate (The "Render"):</strong> The agent finally calls the LLM
                                    with this new, augmented prompt.</div>
                            </div>
                        </div>

                        <div class="bg-white border border-gray-200 p-4 rounded-lg my-4">
                            <h5 class="font-semibold text-black mb-2">Example Augmented Prompt:</h5>
                            <pre class="bg-gray-900 text-gray-100 p-4 rounded text-sm overflow-x-auto"><code>"You are a helpful assistant. Using ONLY the context below, answer the user's question.

Context:
- 'AgentMesh is a protocol...'
- 'It allows for agent-to-agent communication...'

User's Question:
What is Lyzr's AgentMesh?"</code></pre>
                        </div>

                        <div class="lab">
                            <span class="lab-title">Hands-On Lab 2.3: "Chat with Lyzr" RAG Agent</span>
                            <p><strong>Task:</strong> You will build a complete RAG agent from scratch.</p>

                            <div class="mt-3">
                                <h5 class="font-semibold text-black mb-2">Requirements:</h5>
                                <ol class="list-decimal pl-5 space-y-2">
                                    <li>We will provide a <code>lyzr_about.txt</code> file.</li>
                                    <li>Your script will first <strong>index the file</strong>: read it, split it into
                                        chunks, embed them, and save them to a chromadb store.</li>
                                    <li>Your script will then run the <strong>RAG loop</strong>:
                                        <ul class="list-disc pl-5 mt-2 space-y-1">
                                            <li>Take a user's question (e.g., "What super agents does Lyzr have?").</li>
                                            <li><strong>Retrieve</strong> the relevant chunks from the DB.</li>
                                            <li><strong>Augment</strong> the prompt with those chunks.</li>
                                            <li><strong>Generate</strong> the final answer from the LLM.</li>
                                        </ul>
                                    </li>
                                </ol>
                                <p class="mt-3"><strong>Result:</strong> A working "Chat with your Docs" agent. You have
                                    solved the memory problem and built the most in-demand agentic system.</p>
                            </div>
                        </div>

                        <div class="bg-green-50 border-l-4 border-green-500 p-4 my-4 rounded">
                            <h4 class="font-semibold text-green-800 mb-2">Key Learning:</h4>
                            <ul class="list-disc pl-5 text-green-700">
                                <li>RAG (Retrieval-Augmented Generation) combines vector search with LLM generation to
                                    create "open-book" agents.</li>
                                <li>The RAG flow has 3 steps: Retrieve relevant chunks, Augment the prompt with context,
                                    Generate the final answer.</li>
                                <li>RAG agents can answer questions about private data that wasn't in the LLM's training
                                    set.</li>
                                <li>This pattern solves the agent memory problem and enables "Chat with your Docs"
                                    functionality.</li>
                                <li>RAG is the most in-demand agentic system pattern in production environments.</li>
                            </ul>
                        </div>
                    </div>
                </details>

                <!-- Week 3 -->
                <details class="bg-white border border-gray-200 p-6 rounded-lg shadow-sm border border-gray-200">
                    <summary class="text-xl font-semibold text-black">
                        Week 3: Building an Agent Team – Multi-Agent Orchestration
                    </summary>
                    <div class="mt-4 prose prose-slate max-w-none text-black">
                        <p class="text-lg"><strong>Weekly Goal:</strong> To scale our systems by moving from a single
                            "God" agent to a collaborative team of specialized agents. You will learn the core patterns
                            of multi-agent design and orchestrate a workflow, setting the stage for building true "super
                            agents."</p>

                        <hr class="my-4">

                        <h3 class="font-semibold text-lg text-black">Module 3.1: The "God Agent" Problem</h3>
                        <p><strong>Concept:</strong> We'll start with the problem. Our RAG agent from Week 2 is
                            powerful, but what happens when we ask it to do more? "Chat with my docs, and search the
                            web, and write a blog post, and then send me an email." The agent's prompt becomes a
                            bloated, thousand-line mess of instructions and tool definitions. It becomes a "God Agent"
                            that is brittle, hard to debug, and expensive to run.</p>

                        <div class="analogy">
                            <span class="analogy-title">Developer Analogy: The "God Function" vs. Microservices</span>
                            <p>A "God Agent" is like a <strong>"God Function"</strong> or a <strong>Monolith</strong>: A
                                single, 5000-line <code>main.py</code> script that tries to handle database connections,
                                user auth, business logic, and email sending. It's impossible to maintain, test, or
                                update.</p>
                            <p>A <strong>Multi-Agent System</strong> is like a <strong>Microservices
                                    Architecture</strong>: We break the complex problem down. We create:</p>
                            <ul class="list-disc pl-5 mt-2">
                                <li>An auth-service (a <strong>ResearchAgent</strong> that only knows how to search).
                                </li>
                                <li>A user-service (a <strong>WritingAgent</strong> that only knows how to draft text).
                                </li>
                                <li>A notification-service (a <strong>EmailAgent</strong> that only knows how to send
                                    alerts).</li>
                            </ul>
                            <p>This makes our system modular, testable, and scalable. Each agent has a single, clear
                                responsibility.</p>
                        </div>

                        <div class="bg-green-50 border-l-4 border-green-500 p-4 my-4 rounded">
                            <h4 class="font-semibold text-green-800 mb-2">Key Learning:</h4>
                            <ul class="list-disc pl-5 text-green-700">
                                <li>Don't build one agent that does 10 things.</li>
                                <li>Build 10 specialized agents that each do one thing perfectly.</li>
                                <li>The new challenge isn't building agents; it's managing them. This is the problem of
                                </li>
                                <strong>Orchestration</strong>.
                                </li>
                            </ul>
                        </div>

                        <h3 class="font-semibold text-lg text-black mt-6">Module 3.2: The Conductor and the Orchestra
                            (Orchestration Patterns)</h3>
                        <p><strong>Concept:</strong> Now that we have our team of specialist agents (the "orchestra"),
                            we need a "conductor" to tell them what to do and when. This conductor is the
                            <strong>Orchestrator Agent</strong>. We will focus on the two primary orchestration patterns
                            Lyzr uses.
                        </p>

                        <div class="bg-white border border-gray-200 p-4 rounded-lg my-4 text-center">
                            <div class="text-sm text-gray-600 mb-2">Simple Orchestration Diagram:</div>
                            <div class="font-mono text-xs">
                                <div class="bg-blue-200 p-2 rounded mb-2 inline-block">Manager Agent</div>
                                <div class="text-gray-500">↙ ↓ ↘</div>
                                <div class="flex justify-center space-x-4 mt-2">
                                    <div class="bg-white border border-gray-200 p-2 rounded text-xs">Worker 1</div>
                                    <div class="bg-white border border-gray-200 p-2 rounded text-xs">Worker 2</div>
                                    <div class="bg-white border border-gray-200 p-2 rounded text-xs">Worker 3</div>
                                </div>
                            </div>
                        </div>

                        <div class="grid md:grid-cols-2 gap-4 my-6">
                            <div class="bg-white border-l-4 border-black p-4 rounded">
                                <h4 class="font-semibold text-black mb-2">Pattern 1: The "Managerial"
                                    (Hierarchical) Model</h4>
                                <div class="analogy-title text-black mb-2">Analogy: A Tech Lead and Junior Devs
                                </div>
                                <p class="text-black text-sm">You (the user) give a complex feature request to the
                                    Tech Lead (the Manager Agent). The Lead breaks it down into smaller, concrete tasks.
                                </p>
                                <div class="bg-white border border-gray-200 p-2 rounded mt-2 text-xs font-mono">
                                    <div>"Okay, I need a 'frontend' task, a 'backend' task, and a 'database' task."
                                    </div>
                                </div>
                                <p class="text-black text-sm mt-2">The Lead then delegates each task to the right
                                    specialist:</p>
                                <pre class="bg-white border border-gray-200 p-2 rounded mt-1 text-xs"><code>BackendAgent.work(task="create the /api/user endpoint")
FrontendAgent.work(task="build the login form")</code></pre>
                                <p class="text-black text-sm mt-2"><strong>Use Case:</strong> Perfect for dynamic,
                                    complex problems where you don't know all the steps in advance (e.g., "Plan me a
                                    3-day trip to Tokyo").</p>
                            </div>

                            <div class="bg-white border-l-4 border-gray-500 p-4 rounded">
                                <h4 class="font-semibold text-black mb-2">Pattern 2: The "DAG" (Sequential) Model
                                </h4>
                                <div class="analogy-title text-black mb-2">Analogy: A CI/CD Pipeline
                                    (.gitlab-ci.yml)</div>
                                <p class="text-black text-sm">This is a fixed, predictable workflow. The steps are
                                    known in advance, and one step must finish before the next can begin.</p>
                                <div class="bg-white border border-gray-200 p-2 rounded mt-2 text-xs font-mono">
                                    <div>lint-job → test-job → build-job → deploy-job</div>
                                </div>
                                <p class="text-black text-sm mt-2">In this model, there's no dynamic "manager."
                                    It's a predefined graph of operations.</p>
                                <ul class="text-black text-sm mt-2 space-y-1">
                                    <li>• Input goes to ResearchAgent.</li>
                                    <li>• Output of ResearchAgent → WritingAgent.</li>
                                    <li>• Output of WritingAgent → ReviewAgent.</li>
                                </ul>
                                <p class="text-black text-sm mt-2"><strong>Use Case:</strong> Perfect for reliable,
                                    repeatable business processes (e.g., "Take this blog post, generate SEO keywords,
                                    then post it to our blog").</p>
                            </div>
                        </div>

                        <div class="bg-green-50 border-l-4 border-green-500 p-4 my-4 rounded">
                            <h4 class="font-semibold text-green-800 mb-2">Key Learning:</h4>
                            <ul class="list-disc pl-5 text-green-700">
                                <li><strong>Managerial (Dynamic):</strong> Use for creative tasks and unknown problems.
                                </li>
                                <li><strong>DAG (Sequential):</strong> Use for fixed, reliable, and auditable workflows.
                                </li>
                            </ul>
                        </div>

                        <h3 class="font-semibold text-lg text-black mt-6">Module 3.3: "Hello, Team!" – Building a
                            3-Agent Workflow</h3>
                        <p><strong>Concept:</strong> We'll build a "blog post" generator using the <strong>DAG
                                (Sequential) Model</strong> because it's the easiest to build from scratch. This lab
                            will show how to "pipe" the output of one agent into the input of another.</p>

                        <div class="analogy">
                            <span class="analogy-title">Developer Analogy: Piping Commands in Linux</span>
                            <p>This lab is the agentic equivalent of a simple bash command:</p>
                            <pre
                                class="bg-gray-900 text-gray-100 p-3 rounded text-sm mt-2"><code>cat blog_topic.txt | ./research_agent.py | ./writing_agent.py > final_draft.txt</code></pre>
                            <p>We are literally "piping" the state from one agent to the next.</p>
                        </div>

                        <div class="lab">
                            <span class="lab-title">Hands-On Lab 3.3: The "Assembly Line" Agent Team</span>
                            <p><strong>Task:</strong> You will build a 3-agent DAG workflow to write a blog post.</p>

                            <div class="mt-4">
                                <h5 class="font-semibold text-green-700 mb-3">Requirements:</h5>

                                <div class="space-y-4">
                                    <div class="bg-green-50 p-3 rounded border-l-4 border-green-400">
                                        <h6 class="font-semibold text-green-800"><code>research_agent.py</code>:</h6>
                                        <ul class="text-green-700 text-sm mt-1 space-y-1">
                                            <li>• Takes a topic (e.g., "Why Python is great for AI").</li>
                                            <li>• Has a Google Search tool.</li>
                                            <li>• <strong>Output:</strong> A JSON object with a list of 5 bullet points
                                                (e.g., <code>{"research_notes": [...]}</code>).</li>
                                        </ul>
                                    </div>

                                    <div class="bg-blue-50 p-3 rounded border-l-4 border-blue-400">
                                        <h6 class="font-semibold text-blue-800"><code>writing_agent.py</code>:</h6>
                                        <ul class="text-blue-700 text-sm mt-1 space-y-1">
                                            <li>• Takes <code>research_notes</code> as input.</li>
                                            <li>• Has no tools. Its only job is to write.</li>
                                            <li>• <strong>Output:</strong> A JSON object with the full blog post text
                                                (e.g., <code>{"draft": "..."}</code>).</li>
                                        </ul>
                                    </div>

                                    <div class="bg-white border border-gray-200 p-3 rounded border-l-4 border-black">
                                        <h6 class="font-semibold text-black"><code>review_agent.py</code>:</h6>
                                        <ul class="text-black text-sm mt-1 space-y-1">
                                            <li>• Takes a <code>draft</code> as input.</li>
                                            <li>• Has no tools. Its job is to review and give a score.</li>
                                            <li>• <strong>Output:</strong> A JSON object with a rating and comments
                                                (e.g.,
                                                <code>{"rating": 8, "comments": "Good, but a bit short."}</code>).
                                            </li>
                                        </ul>
                                    </div>

                                    <div class="bg-white border border-gray-200 p-3 rounded border-l-4 border-black">
                                        <h6 class="font-semibold text-black"><code>main.py</code> (The Orchestrator):
                                        </h6>
                                        <p class="text-black text-sm mt-1">Your main script will call each agent in
                                            order, take its output, and use it as the input for the next agent, printing
                                            the final result.</p>
                                    </div>
                                </div>

                                <div class="bg-green-50 border-l-4 border-green-500 p-4 my-4 rounded">
                                    <h5 class="font-semibold text-black mb-2">Final "Aha!" Moment:</h5>
                                    <p class="text-black text-sm">At the end of this lab, we'll pose a question:
                                        "This
                                        works great, but our <code>research_agent</code> and <code>writing_agent</code>
                                        both needed to be told about the Google Search tool. What if we had 20 agents
                                        and 10 tools? How do we manage that?"</p>
                                    <p class="text-black text-sm mt-2">This <strong>"N x M" problem</strong> (20
                                        agents x 10 tools) is the perfect lead-in to Week 4, where we introduce
                                        <strong>MCP (Model Context Protocol)</strong> as the elegant solution.
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                </details>

                <!-- Week 4 -->
                <details class="bg-white border border-gray-200 p-6 rounded-lg shadow-sm border border-gray-200">
                    <summary class="text-xl font-semibold text-black">
                        Week 4: The Lyzr Deep Dive – From Prototype to Production "Super Agent"
                    </summary>
                    <div class="mt-4 prose prose-slate max-w-none text-black">
                        <p class="text-lg"><strong>Weekly Goal:</strong> To bridge the gap from a "from-scratch"
                            prototype to a scalable, production-grade agentic system. You will solve the "N x M" tool
                            integration problem using the Model Context Protocol (MCP) and synthesize all your skills
                            into a capstone project: building a "super agent" modeled on Lyzr's <strong>Diane for
                                HR</strong>.</p>

                        <hr class="my-4">

                        <h3 class="font-semibold text-lg text-black">Module 4.1: The "Integration Hell" Problem (The
                            "N x M" Problem)</h3>
                        <p><strong>Concept:</strong> We'll start by formalizing the "Aha!" moment from Lab 3.3. In our
                            simple 3-agent team, we already saw a problem: how do we tell all our agents about the tools
                            they can use? What if we have 20 agents and 10 tools? Do we copy-paste 10 tool definitions
                            into 20 different system prompts? This is the "N x M" problem, and it's a maintenance
                            nightmare.</p>

                        <div class="analogy">
                            <span class="analogy-title">Developer Analogy: Hard-Coded fetch vs. a Service Mesh (like
                                gRPC or Istio)</span>
                            <div class="space-y-3">
                                <div class="bg-white border border-gray-200 p-3 rounded border-l-4 border-gray-500">
                                    <h5 class="font-semibold text-black">Our "From-Scratch" Way (Weeks 1-3):</h5>
                                    <p class="text-black text-sm">This is like hard-coding
                                        <code>fetch('http://weather-api.com/...')</code> inside every single one of your
                                        microservices. It works, but it's brittle. What happens when the API URL
                                        changes? You have to update 20 services.
                                    </p>
                                </div>
                                <div class="bg-white border border-gray-200 p-3 rounded border-l-4 border-black">
                                    <h5 class="font-semibold text-black">The "Production" Way (MCP):</h5>
                                    <p class="text-black text-sm">We introduce a "service mesh." You build your tool
                                        <strong>once</strong> as an independent "service." All your agents ("clients")
                                        just connect to the mesh, which handles service discovery. The agent simply
                                        says, "I need the 'weather' service," and the mesh connects them. The agent
                                        doesn't know or care where the service lives. This is what the <strong>Model
                                            Context Protocol (MCP)</strong> does for AI agents.
                                    </p>
                                </div>
                            </div>
                        </div>

                        <div class="bg-green-50 border-l-4 border-green-500 p-4 my-4 rounded">
                            <h4 class="font-semibold text-green-800 mb-2">Key Learning:</h4>
                            <ul class="list-disc pl-5 text-green-700 space-y-1">
                                <li><strong>MCP (Model Context Protocol)</strong> is an open standard that decouples
                                    agents from their tools.</li>
                                <li>Tools are exposed as <strong>"MCP Servers."</strong></li>
                                <li>Agents act as <strong>"MCP Clients"</strong> that can discover and use any available
                                    tool on the network, without needing it hard-coded in their prompt.</li>
                                <li>This is the solution for building scalable, interoperable, and maintainable agentic
                                    systems.</li>
                            </ul>
                        </div>

                        <h3 class="font-semibold text-lg text-black mt-6">Module 4.2: Refactoring Our Team with MCP
                        </h3>
                        <p><strong>Concept:</strong> We will take our "Assembly Line" blog post generator from Lab 3.3
                            and refactor it to use the MCP standard. This will make the "N x M" problem and its solution
                            tangible.</p>

                        <div class="analogy">
                            <span class="analogy-title">Developer Analogy: The "Before" and "After" Refactor</span>
                            <p>This is a classic refactoring lab. We'll take our messy, "hard-coded"
                                <code>main.py</code> from Week 3 and refactor it to use a professional design pattern,
                                resulting in cleaner, more modular code.
                            </p>
                        </div>

                        <div class="lab">
                            <span class="lab-title">Hands-On Lab 4.2: The "Service Mesh" Refactor</span>
                            <p><strong>Task:</strong> You will refactor your 3-agent workflow from Week 3.</p>

                            <div class="grid md:grid-cols-2 gap-4 mt-4">
                                <div class="bg-white border border-gray-200 p-4 rounded border-l-4 border-gray-500">
                                    <h5 class="font-semibold text-black mb-2">"Before" (Our Lab 3.3 code):</h5>
                                    <p class="text-black text-sm"><code>research_agent.py</code> has the Google
                                        Search
                                        tool definition hard-coded in its system prompt.</p>
                                </div>
                                <div class="bg-white border border-gray-200 p-4 rounded border-l-4 border-black">
                                    <h5 class="font-semibold text-black mb-2">"After" (Our Lab 4.2 code):</h5>
                                    <ul class="text-black text-sm space-y-1">
                                        <li>• We will provide a separate script, <code>tool_server.py</code>, that runs
                                            a simple MCP Server exposing the Google Search tool.</li>
                                        <li>• You will <strong>delete</strong> the tool definition from your
                                            research_agent's prompt.</li>
                                        <li>• You will modify <code>research_agent.py</code> to be an MCP Client that
                                            connects to the tool_server to discover and use the Google Search tool.</li>
                                    </ul>
                                </div>
                            </div>

                            <p class="mt-4 p-3 bg-white border-l-4 border-black text-black text-sm rounded">
                                <strong>Result:</strong> Your agent's prompt is now clean and focused only on its task.
                                And any other agent we build can now also connect to <code>tool_server</code> and use
                                Google Search for free. We have solved the "N x M" problem.
                            </p>
                        </div>

                        <h3 class="font-semibold text-lg text-black mt-6">Module 4.3: Capstone Project – Building
                            "Diane-Lite" (An HR Super Agent)</h3>
                        <p><strong>Concept:</strong> This is the final project. You will synthesize everything you've
                            learned over the last four weeks—the agent loop, RAG, multi-agent orchestration, and tool
                            use—to build a simplified version of Lyzr's <strong>Diane for HR</strong> super agent.</p>

                        <div class="bg-white border-l-4 border-black p-4 my-4 rounded border border-gray-200">
                            <h4 class="font-semibold text-black mb-2">The Project Brief:</h4>
                            <p class="text-black text-sm">Your task is to build "Diane-Lite," an HR assistant that
                                can help a hiring manager. The user must be able to make a single, high-level request,
                                and your agent team must orchestrate the entire workflow to get the answer.</p>
                        </div>

                        <div class="bg-white border border-gray-200 p-4 rounded-lg my-4">
                            <h4 class="font-semibold text-black mb-3">The Architecture (Managerial Model):</h4>
                            <p class="text-black text-sm mb-3">You will build a multi-agent system using the
                                "Managerial" (Hierarchical) model from Week 3.</p>

                            <div class="grid gap-3">
                                <div class="bg-white border border-gray-200 p-3 rounded">
                                    <h6 class="font-semibold text-black"><strong>Diane-Manager</strong> (The
                                        Conductor):</h6>
                                    <p class="text-black text-sm">The only agent the user talks to. It takes the
                                        goal, breaks it down, and delegates tasks to its specialist workers.</p>
                                </div>
                                <div class="flex space-x-3">
                                    <div class="bg-white border border-gray-200 p-3 rounded flex-1">
                                        <h6 class="font-semibold text-black"><strong>HR-Policy-Agent</strong>
                                            (Worker):</h6>
                                        <p class="text-black text-sm">A RAG agent (from Week 2) that is connected to
                                            a vector store of <code>hr_policy.pdf</code>. Its only job is to answer
                                            questions about company policy.</p>
                                    </div>
                                    <div class="bg-white border border-gray-200 p-3 rounded flex-1">
                                        <h6 class="font-semibold text-black"><strong>Resume-Screener-Agent</strong>
                                            (Worker):</h6>
                                        <p class="text-black text-sm">A RAG agent that is connected to a vector
                                            store of <code>resumes/</code>. Its only job is to find candidates that
                                            match a job description.</p>
                                    </div>
                                    <div class="bg-white border border-gray-200 p-3 rounded flex-1">
                                        <h6 class="font-semibold text-black"><strong>Calendar-Agent</strong>
                                            (Worker):</h6>
                                        <p class="text-black text-sm">A simple agent (from Week 1) that has a
                                            single tool: <code>find_available_interview_slot(date_range)</code>.</p>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="lab">
                            <span class="lab-title">Hands-On Lab 4.3: The "Super Agent" Workflow</span>
                            <p><strong>Task:</strong> You will assemble all four agents and run a final "integration
                                test" with a complex, high-level user prompt.</p>

                            <div class="bg-gray-900 text-gray-100 p-4 rounded-lg my-4">
                                <h5 class="text-gray-300 font-semibold mb-2">User Prompt:</h5>
                                <p class="text-sm italic">"Hi, I'm hiring a 'Senior Python Developer.' First, what is
                                    our company's policy on remote work? Second, please find the top 3 candidates for
                                    that role from our resume folder and book a 1-hour interview slot for them next
                                    Tuesday."</p>
                            </div>

                            <div class="bg-green-50 border-l-4 border-green-500 p-4 my-4 rounded">
                                <h5 class="font-semibold text-black mb-3">What you will watch (The "Aha!" Moment):
                                </h5>
                                <p class="text-black text-sm mb-3">You will see the <strong>Diane-Manager</strong>
                                    agent's "thoughts" as it orchestrates the entire process:</p>

                                <div class="space-y-2 text-sm">
                                    <div class="bg-white border border-gray-200 p-2 rounded border-l-2 border-black">
                                        <strong class="text-black">Manager Thought:</strong> <span
                                            class="text-black">"The user has three requests. I'll do them in order.
                                            First, the policy question."</span>
                                    </div>
                                    <div class="bg-white border border-gray-200 p-2 rounded">
                                        <strong class="text-black">Manager → HR-Policy-Agent:</strong> <span
                                            class="text-black">"What is the policy on remote work?"</span><br>
                                        <strong class="text-black">HR-Policy-Agent → Manager:</strong> <span
                                            class="text-black">(Returns the RAG-generated answer).</span>
                                    </div>
                                    <div class="bg-white border border-gray-200 p-2 rounded border-l-2 border-black">
                                        <strong class="text-black">Manager Thought:</strong> <span
                                            class="text-black">"Great. Now for the resumes. I'll call the
                                            screener."</span>
                                    </div>
                                    <div class="bg-white border border-gray-200 p-2 rounded">
                                        <strong class="text-black">Manager → Resume-Screener-Agent:</strong> <span
                                            class="text-black">"Find top 3 candidates for 'Senior Python
                                            Developer'."</span><br>
                                        <strong class="text-black">Resume-Screener-Agent → Manager:</strong> <span
                                            class="text-black">(Returns ["candidate_A.pdf", "candidate_B.pdf",
                                            "candidate_C.pdf"]).</span>
                                    </div>
                                    <div class="bg-white border border-gray-200 p-2 rounded border-l-2 border-black">
                                        <strong class="text-black">Manager Thought:</strong> <span
                                            class="text-black">"Got the candidates. Now I'll find a calendar
                                            slot."</span>
                                    </div>
                                    <div class="bg-white border border-gray-200 p-2 rounded">
                                        <strong class="text-black">Manager → Calendar-Agent:</strong> <span
                                            class="text-black">"Find a 1-hour slot next Tuesday."</span><br>
                                        <strong class="text-black">Calendar-Agent → Manager:</strong> <span
                                            class="text-black">(Returns {"slot": "Tuesday, 3:00 PM - 4:00
                                            PM"}).</span>
                                    </div>
                                    <div class="bg-white border border-gray-200 p-3 rounded">
                                        <strong class="text-black">Manager → User:</strong> <span
                                            class="text-black">(Generates the final, comprehensive
                                            answer):</span><br>
                                        <div class="mt-2 italic text-black text-xs">
                                            "Here is the information you requested:<br>
                                            • Our remote work policy is...<br>
                                            • The top 3 candidates are: Candidate A, B, and C.<br>
                                            • I have tentatively booked an interview slot for them on Tuesday at 3:00
                                            PM."
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <h3 class="font-semibold text-lg text-black mt-6">Module 4.4: The Road Ahead</h3>
                        <p><strong>Concept:</strong> A final wrap-up on the "so what?" of agent development. Now that
                            you can build an agent, how do you know it's good?</p>

                        <div class="grid md:grid-cols-3 gap-4 mt-4">
                            <div class="bg-white border-l-4 border-black p-4 rounded">
                                <h4 class="font-semibold text-black mb-2">Evaluation:</h4>
                                <p class="text-black text-sm">How to test an agent. You can't just use
                                    <code>pytest</code> and check for <code>assert x == 5</code>. We'll discuss
                                    "AI-as-a-grader" (using one LLM to "grade" another's output).
                                </p>
                            </div>
                            <div class="bg-white border-l-4 border-black p-4 rounded">
                                <h4 class="font-semibold text-black mb-2">Safety & Guardrails:</h4>
                                <p class="text-black text-sm">What's to stop your agent from booking 100 meetings or
                                    sending an angry email? We'll talk about the importance of "human-in-the-loop"
                                    approval steps for any agent that <em>acts</em> (i.e., modifies a database, sends an
                                    email).</p>
                            </div>
                            <div class="bg-white border-l-4 border-black p-4 rounded">
                                <h4 class="font-semibold text-black mb-2">The Future:</h4>
                                <p class="text-black text-sm">A final, inspiring look at the future of the "Agent
                                    Movement."</p>
                            </div>
                        </div>
                    </div>
                </details>
            </div>

        </section>

        <!-- Part 2: The Video -->
        <section>
            <h2 class="text-2xl font-semibold text-black mb-4">Part 2: 3-Minute Teaching Video</h2>
            <p class="mb-4 text-black">For the video portion, I chose to teach about <strong>"The Memory Problem in
                    LLMs"</strong>. This fundamental concept explains why agents need external memory systems and how
                this limitation leads to the development of RAG and vector databases - providing a crucial "aha!" moment
                for developers.</p>

            <div class="bg-white border border-gray-200 p-6 rounded-lg shadow-sm border border-gray-200">
                <div class="aspect-w-16 aspect-h-9 rounded-lg overflow-hidden shadow-lg">
                    <iframe class="w-full h-96 rounded-lg" src="https://www.youtube.com/embed/uLdySB97Ks0"
                        title="Agent Building for Developers - The Memory Problem in LLMs" frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                        allowfullscreen>
                    </iframe>
                </div>

                <div class="mt-4 p-4 bg-white rounded-lg">
                    <h3 class="font-semibold text-black mb-2">Video Overview:</h3>
                    <p class="text-black text-sm">This 3-minute tutorial explains the fundamental memory problem in
                        Large Language Models - why they can't remember large amounts of information and how this
                        limitation led to the development of vector databases and RAG systems. The video demonstrates
                        the context window problem and introduces the concept of external memory for AI agents.</p>
                </div>
            </div>
        </section>

</body>

</html>